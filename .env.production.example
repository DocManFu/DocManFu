# =============================================================================
# DocManFu Production Environment Configuration
# Copy to .env and fill in required values before starting
# =============================================================================

# --- Required ---

# Database password (REQUIRED — generate with: openssl rand -hex 16)
POSTGRES_PASSWORD=

# JWT secret key (REQUIRED — generate with: openssl rand -hex 32)
JWT_SECRET_KEY=

# --- Application ---

APP_NAME=DocManFu
APP_VERSION=0.1.0
LOG_LEVEL=WARNING
UPLOAD_DIR=uploads
MAX_FILE_SIZE_MB=50

# CORS origins — set to your domain(s)
CORS_ORIGINS=["https://docs.example.com"]

# JWT settings
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# --- AI Provider ---
# Options: none, ollama, openai, anthropic
AI_PROVIDER=none

# For Ollama in Docker (start with: ./prod up -d --profile ollama)
# GPU requires NVIDIA Container Toolkit. For CPU-only: --profile ollama-cpu
# AI_PROVIDER=ollama
# AI_BASE_URL=http://ollama:11434
# AI_MODEL=llama3.2
# AI_VISION_MODEL=granite3.2-vision

# For Ollama running natively on macOS host (GPU via Metal):
# AI_PROVIDER=ollama
# AI_BASE_URL=http://host.docker.internal:11434
# AI_MODEL=llama3.2
# AI_VISION_MODEL=granite3.2-vision

# For OpenAI:
# AI_PROVIDER=openai
# AI_API_KEY=sk-...
# AI_MODEL=gpt-4o-mini

# For Anthropic:
# AI_PROVIDER=anthropic
# AI_API_KEY=sk-ant-...
# AI_MODEL=claude-sonnet-4-5-20250929

AI_API_KEY=
AI_MODEL=
AI_VISION_MODEL=
AI_MAX_TEXT_LENGTH=4000
AI_TIMEOUT=60
AI_MAX_PAGES=5
AI_VISION_DPI=150

# --- OCR ---

OCR_LANGUAGE=eng
OCR_DPI=300
OCR_SKIP_TEXT=true
OCR_CLEAN=true

# --- Tuning ---

# Number of uvicorn workers for the API service (default: 2)
API_WORKERS=2

# Number of Celery worker processes (default: 2)
WORKER_CONCURRENCY=2

# Host port for the frontend (default: 8080)
FRONTEND_PORT=8080

# --- Celery ---

CELERY_TASK_MAX_RETRIES=3
CELERY_TASK_RETRY_DELAY=60
